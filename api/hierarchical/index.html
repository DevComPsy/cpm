<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>cpm.hierarchical - CPM library</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../assets/_mkdocstrings.css" rel="stylesheet" />
        <link href="../../style.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "cpm.hierarchical";
        var mkdocs_page_input_path = "api/hierarchical.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/bash.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/json.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/markdown.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/makefile.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> CPM library
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Getting Started</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../troubleshooting/">Troubleshooting</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../roadmap/">Roadmap</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/example1/">Example 1: An associative learning model and blocking</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/example2/">Example 2: Reinforcement learning with a two-armed bandit.</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/example3/">Example 3: Estimating Empirical Priors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/example4/">Example 4: Scale to hypercomputing cluster</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/example5/">Example 5: Estimating meta-d (metacognitive efficiency)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">API Reference</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../generators/">cpm.generators</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../models/">cpm.models</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../optimisation/">cpm.optimisation</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">cpm.hierarchical</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#cpm.hierarchical.EmpiricalBayes">EmpiricalBayes</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.EmpiricalBayes.diagnostics">diagnostics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.EmpiricalBayes.optimise">optimise</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.EmpiricalBayes.parameters">parameters</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.EmpiricalBayes.stair">stair</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes">VariationalBayes</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.check_convergence">check_convergence</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.diagnostics">diagnostics</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.get_lme">get_lme</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.optimise">optimise</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.run_vb">run_vb</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.ttest">ttest</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#cpm.hierarchical.VariationalBayes.update_population">update_population</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../applications/">cpm.applications</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utils/">cpm.utils</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">CPM library</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">API Reference</li>
      <li class="breadcrumb-item active">cpm.hierarchical</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="cpmhierarchical">cpm.hierarchical</h1>


<div class="doc doc-object doc-class">



<h2 id="cpm.hierarchical.EmpiricalBayes" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">cpm</span><span class="o">.</span><span class="n">hierarchical</span><span class="o">.</span><span class="n">EmpiricalBayes</span><span class="p">(</span><span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;minimise&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">chain</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents first">


        <p>Implements an Expectation-Maximisation algorithm for the optimisation of the group-level distributions of the parameters of a model from subject-level parameter estimations.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>optimiser</code></b>
                  (<code><span title="object">object</span></code>, default:
                      <code>None</code>
)
              â€“
              <div class="doc-md-description">
                <p>The initialized Optimiser object. It must use an optimisation algorithm that also returns the Hessian matrix.</p>
              </div>
            </li>
            <li>
              <b><code>objective</code></b>
                  (<code><span title="str">str</span></code>, default:
                      <code>&#39;minimise&#39;</code>
)
              â€“
              <div class="doc-md-description">
                <p>The objective of the optimisation, either 'maximise' or 'minimise'. Default is 'minimise'. Only affects how we arrive at the participant-level <em>a posteriori</em> parameter estimates.</p>
              </div>
            </li>
            <li>
              <b><code>iteration</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>1000</code>
)
              â€“
              <div class="doc-md-description">
                <p>The maximum number of iterations. Default is 1000.</p>
              </div>
            </li>
            <li>
              <b><code>tolerance</code></b>
                  (<code><span title="float">float</span></code>, default:
                      <code>1e-06</code>
)
              â€“
              <div class="doc-md-description">
                <p>The tolerance for convergence. Default is 1e-6.</p>
              </div>
            </li>
            <li>
              <b><code>chain</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>4</code>
)
              â€“
              <div class="doc-md-description">
                <p>The number of random parameter initialisations. Default is 4.</p>
              </div>
            </li>
            <li>
              <b><code>quiet</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>False</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to suppress the output. Default is False.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<details class="note" open>
  <summary>Notes</summary>
  <p>The EmpiricalBayes class implements an Expectation-Maximisation algorithm for the optimisation of the group-level distributions of the parameters of a model from subject-level parameter estimations. For the complete description of the method, please see Gershman (2016).</p>
<p>The fitting function must return the <a href="https://en.wikipedia.org/wiki/Hessian_matrix">Hessian matrix</a> of the optimisation.
The Hessian matrix is then used in establishing the within-subject variance of the parameters.
It is also important to note that we will require the Hessian matrix of second derivatives of the <strong>negative log posterior</strong> (Gershman, 2016, p. 3).
This requires us to minimise or maximise the log posterior density as opposed to a simple log likelihood, when estimating participant-level parameters.</p>
<p>In the current implementation, we try to calculate the second derivative of the negative log posterior density function according to the following algorithm:</p>
<ol>
<li>Attempt to use <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition">Cholesky decomposition</a>.</li>
<li>If fails, attempt to use <a href="https://en.wikipedia.org/wiki/LU_decomposition">LU decomposition</a>.</li>
<li>If fails, attempt to use <a href="https://en.wikipedia.org/wiki/QR_decomposition">QR decomposition</a>.</li>
<li>If the result is a complex number with zero imaginary part, keep the real part.</li>
</ol>
<p>In addition, because the the Hessian matrix should correspond to the precision matrix, hence its inverse is the variance-covariance matrix, we will use its inverse to calculate the within-subject variance of the parameters. If the algorithm fails to calculate the inverse of the Hessian matrix, it will use the <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">Moore-Penrose pseudoinverse</a> instead.</p>
<p>The current implementation also controls for some <strong>edge-cases</strong> that are not covered by the algorithm above:</p>
<ul>
<li>When calculating the within-subject variance via the Hessian matrix, the algorithm clips the variance to a minimum value of 1e-6 to avoid numerical instability.</li>
<li>When calculating the within-subject variance via the Hessian matrix, the algorithm sets any non-finite or non-positive values to NaN.</li>
<li>If the second derivative of the negative log posterior density function is not finite, we set the log determinant to -1e6.</li>
</ul>
</details>

<details class="references" open>
  <summary>References</summary>
  <p>Gershman, S. J. (2016). Empirical priors for reinforcement learning models. Journal of Mathematical Psychology, 71, 1-6.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">cpm.optimisation</span><span class="w"> </span><span class="kn">import</span> <span class="n">EmpiricalBayes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">cpm.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeltaRule</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">cpm.optimisation</span><span class="w"> </span><span class="kn">import</span> <span class="n">FminBound</span><span class="p">,</span> <span class="n">minimise</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DeltaRule</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimiser</span> <span class="o">=</span> <span class="n">FminBound</span><span class="p">(</span>
<span class="go">    model=model,</span>
<span class="go">    data=data,</span>
<span class="go">    initial_guess=None,</span>
<span class="go">    number_of_starts=2,</span>
<span class="go">    minimisation=minimise.LogLikelihood.bernoulli,</span>
<span class="go">    parallel=False,</span>
<span class="go">    prior=True,</span>
<span class="go">    ppt_identifier=&quot;ppt&quot;,</span>
<span class="go">    display=False,</span>
<span class="go">    maxiter=200,</span>
<span class="go">    approx_grad=True</span>
<span class="go">    )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eb</span> <span class="o">=</span> <span class="n">EmpiricalBayes</span><span class="p">(</span><span class="n">optimiser</span><span class="o">=</span><span class="n">optimiser</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">chain</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eb</span><span class="o">.</span><span class="n">optimise</span><span class="p">()</span>
</code></pre></div>










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.EmpiricalBayes.diagnostics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">diagnostics</span><span class="p">(</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Returns the convergence diagnostics plots for the group-level hyperparameters.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>show</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>True</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to show the plots. Default is True.</p>
              </div>
            </li>
            <li>
              <b><code>save</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>False</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to save the plots. Default is False.</p>
              </div>
            </li>
            <li>
              <b><code>path</code></b>
                  (<code><span title="str">str</span></code>, default:
                      <code>None</code>
)
              â€“
              <div class="doc-md-description">
                <p>The path to save the plots. Default is None.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<details class="note" open>
  <summary>Notes</summary>
  <p>The convergence diagnostics plots show the convergence of the log model evidence, the means, and the standard deviations of the group-level hyperparameters.
It also shows the distribution of the means and the standard deviations of the group-level hyperparameters sampled for each chain.</p>
</details>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.EmpiricalBayes.optimise" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">optimise</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>This method runs the Expectation-Maximisation algorithm for the optimisation of the group-level distributions of the parameters of a model from subject-level parameter estimations. This is essentially the main function that runs the algorithm for multiple chains with random starting points for the priors.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.EmpiricalBayes.parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">parameters</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Returns the estimated individual-level parameters for each iteration and chain.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
              â€“
              <div class="doc-md-description">
                <p>The estimated individual-level parameters for each iteration and chain.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.EmpiricalBayes.stair" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">stair</span><span class="p">(</span><span class="n">chain_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>The main function that runs the Expectation-Maximisation algorithm for the optimisation of the group-level distributions of the parameters of a model from subject-level parameter estimations. This is essentially a single chain.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
                  <code><span title="dict">dict</span></code>
              â€“
              <div class="doc-md-description">
                <p>A dictionary containing the log model evidence, the hyperparameters of the group-level distributions, and the parameters of the model.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="cpm.hierarchical.VariationalBayes" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">cpm</span><span class="o">.</span><span class="n">hierarchical</span><span class="o">.</span><span class="n">VariationalBayes</span><span class="p">(</span><span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;minimise&#39;</span><span class="p">,</span> <span class="n">iteration</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">tolerance_lme</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">tolerance_param</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">chain</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hyperpriors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">convergence</span><span class="o">=</span><span class="s1">&#39;parameters&#39;</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents first">


        <p>Performs hierarchical Bayesian estimation of a given model using variational (approximate) inference methods, a reduced version of the Hierarchical Bayesian Inference (HBI) algorithm proposed by Piray et al. (2019), to exclude model comparison and selection.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>optimiser</code></b>
                  (<code><span title="object">object</span></code>, default:
                      <code>None</code>
)
              â€“
              <div class="doc-md-description">
                <p>The initialized Optimiser object. It must use an optimisation algorithm that also returns the Hessian matrix.</p>
              </div>
            </li>
            <li>
              <b><code>objective</code></b>
                  (<code><span title="str">str</span></code>, default:
                      <code>&#39;minimise&#39;</code>
)
              â€“
              <div class="doc-md-description">
                <p>The objective of the optimisation, either 'maximise' or 'minimise'. Default is 'minimise'. Only affects how we arrive at the participant-level <em>a posteriori</em> parameter estimates.</p>
              </div>
            </li>
            <li>
              <b><code>iteration</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>50</code>
)
              â€“
              <div class="doc-md-description">
                <p>The maximum number of iterations. Default is 1000.</p>
              </div>
            </li>
            <li>
              <b><code>tolerance_lme</code></b>
                  (<code><span title="float">float</span></code>, default:
                      <code>0.001</code>
)
              â€“
              <div class="doc-md-description">
                <p>The tolerance for convergence with respect to the log model evidence. Default is 1e-3.</p>
              </div>
            </li>
            <li>
              <b><code>tolerance_param</code></b>
                  (<code><span title="float">float</span></code>, default:
                      <code>0.001</code>
)
              â€“
              <div class="doc-md-description">
                <p>The tolerance for convergence with respect to the "normalized" means of parameters. Default is 1e-3.</p>
              </div>
            </li>
            <li>
              <b><code>chain</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>4</code>
)
              â€“
              <div class="doc-md-description">
                <p>The number of random parameter initialisations. Default is 4.</p>
              </div>
            </li>
            <li>
              <b><code>hyperpriors</code></b>
              â€“
              <div class="doc-md-description">
                <p>A dictionary of given parameter values of the prior distributions on the population-level parameters (means mu and precisions tau). See Notes for details. Default is None.</p>
              </div>
            </li>
            <li>
              <b><code>convergence</code></b>
                  (<code><span title="str">str</span></code>, default:
                      <code>&#39;parameters&#39;</code>
)
              â€“
              <div class="doc-md-description">
                <p>The convergence criterion. Default is 'parameters'. Options are 'lme' and 'parameters'.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<details class="note" open>
  <summary>Notes</summary>
  <p>The hyperprios are as follows:</p>
<ul>
<li><code>a0</code> : array-like
    Vector of means of the normal prior on the population-level means, mu.</li>
<li><code>b</code> : float
    Scalar value that is multiplied with population-level precisions, tau, to determine the standard deviations of the normal prior on the population-level means, mu.</li>
<li><code>v</code> : float
    Scalar value that is used to determine the shape parameter (nu) of the gamma prior on population-level precisions, tau.</li>
<li><code>s</code> : array-like
    Vector of values that serve as lower bounds on the scale parameters (sigma) of the gamma prior on population-level precisions, tau.</li>
</ul>
<p>With the number of parameters as N, the default values are as follows:</p>
<ul>
<li><code>a0</code> : np.zeros(N)</li>
<li><code>b</code> : 1</li>
<li><code>v</code> : 0.5</li>
<li><code>s</code> : np.repeat(0.01, N)</li>
</ul>
<p>The convergence criterion can be set to 'lme' or 'parameters'. If set to 'lme', the algorithm will stop when the log model evidence converges. If set to 'parameters', the algorithm will stop when the "normalized" means of the population-level parameters converge.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <p>Piray, P., Dezfouli, A., Heskes, T., Frank, M. J., &amp; Daw, N. D. (2019). Hierarchical Bayesian inference for concurrent model fitting and comparison for group studies. PLoS computational biology, 15(6), e1007043.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    










  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.check_convergence" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">check_convergence</span><span class="p">(</span><span class="n">lme_new</span><span class="p">,</span> <span class="n">lme_old</span><span class="p">,</span> <span class="n">param_snr_new</span><span class="p">,</span> <span class="n">param_snr_old</span><span class="p">,</span> <span class="n">iter_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">use_lme</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Function to check if the algorithm has converged.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>lme_new</code></b>
                  (<code><span title="float">float</span></code>)
              â€“
              <div class="doc-md-description">
                <p>The new log model evidence.</p>
              </div>
            </li>
            <li>
              <b><code>lme_old</code></b>
                  (<code><span title="float">float</span></code>)
              â€“
              <div class="doc-md-description">
                <p>The old log model evidence.</p>
              </div>
            </li>
            <li>
              <b><code>param_snr_new</code></b>
                  (<code><span title="array">array</span> - <span title="like">like</span></code>)
              â€“
              <div class="doc-md-description">
                <p>The new standardised estimates of population-level means.</p>
              </div>
            </li>
            <li>
              <b><code>param_snr_old</code></b>
                  (<code><span title="array">array</span> - <span title="like">like</span></code>)
              â€“
              <div class="doc-md-description">
                <p>The old standardised estimates of population-level means.</p>
              </div>
            </li>
            <li>
              <b><code>iter_idx</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>0</code>
)
              â€“
              <div class="doc-md-description">
                <p>The iteration index. Default is 0.</p>
              </div>
            </li>
            <li>
              <b><code>use_lme</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>True</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to use the log model evidence for checking convergence. Default is True.</p>
              </div>
            </li>
            <li>
              <b><code>use_param</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>True</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to use the standardised estimates of population-level means for checking convergence. Default is True.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
<b><code>convergence</code></b>(                  <code><span title="bool">bool</span></code>
)              â€“
              <div class="doc-md-description">
                <p>Whether the algorithm has converged.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.diagnostics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">diagnostics</span><span class="p">(</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Returns the convergence diagnostics plots for the group-level hyperparameters.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>show</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>True</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to show the plots. Default is True.</p>
              </div>
            </li>
            <li>
              <b><code>save</code></b>
                  (<code><span title="bool">bool</span></code>, default:
                      <code>False</code>
)
              â€“
              <div class="doc-md-description">
                <p>Whether to save the plots. Default is False.</p>
              </div>
            </li>
            <li>
              <b><code>path</code></b>
                  (<code><span title="str">str</span></code>, default:
                      <code>None</code>
)
              â€“
              <div class="doc-md-description">
                <p>The path to save the plots. Default is None.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<details class="note" open>
  <summary>Notes</summary>
  <p>The convergence diagnostics plots show the convergence of the log model evidence, the means, and the standard deviations of the group-level hyperparameters.
It also shows the distribution of the means and the standard deviations of the group-level hyperparameters sampled for each chain.</p>
</details>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.get_lme" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_lme</span><span class="p">(</span><span class="n">log_post</span><span class="p">,</span> <span class="n">hessian</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Function to approximate the participant-wise log model evidence using Laplace's approximation.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>log_post</code></b>
                  (<code><span title="array">array</span> - <span title="like">like</span></code>)
              â€“
              <div class="doc-md-description">
                <p>Participant-wise value of log posterior density function at the mode (i.e., MAP parameter estimates).</p>
              </div>
            </li>
            <li>
              <b><code>hessian</code></b>
                  (<code><span title="array">array</span> - <span title="like">like</span></code>)
              â€“
              <div class="doc-md-description">
                <p>Participant-wise Hessian matrix of log posterior density function evaluated at the mode (i.e., MAP parameter estimates).</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
<b><code>lme</code></b>(                  <code><span title="array">array</span></code>
)              â€“
              <div class="doc-md-description">
                <p>Participant-wise log model evidence.</p>
              </div>
            </li>
            <li>
<b><code>lme_sum</code></b>(                  <code><span title="float">float</span></code>
)              â€“
              <div class="doc-md-description">
                <p>Summed log model evidence.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.optimise" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">optimise</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Run the Variational Bayes algorithm for multiple chains.</p>


    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.run_vb" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">run_vb</span><span class="p">(</span><span class="n">chain_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Run the hierarchical Bayesian inference algorithm.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>chain_index</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>0</code>
)
              â€“
              <div class="doc-md-description">
                <p>The chain index. Default is 0.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
<b><code>output</code></b>(                  <code><span title="dict">dict</span></code>
)              â€“
              <div class="doc-md-description">
                <p>Dictionary of results.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.ttest" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">ttest</span><span class="p">(</span><span class="n">null</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Perform a one-sample Student's t-test on the estimated values of population-level means with respect to given null hypothesis values.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>null</code></b>
                  (<code><span title="dict">dict</span> or <span title="pandas.DataFrame">DataFrame</span></code>, default:
                      <code>None</code>
)
              â€“
              <div class="doc-md-description">
                <p>The null hypothesis values for the population-level means for each parameters.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
<b><code>t_df</code></b>(                  <code><span title="pandas.DataFrame">DataFrame</span></code>
)              â€“
              <div class="doc-md-description">
                <p>The results of the t-test.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="cpm.hierarchical.VariationalBayes.update_population" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_population</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">hessian</span><span class="p">,</span> <span class="n">lme</span><span class="p">,</span> <span class="n">iter_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">chain_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Function to update the population-level parameters based on the results of participant-wise optimisation.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>param</code></b>
                  (<code><span title="array">array</span> - <span title="like">like</span></code>)
              â€“
              <div class="doc-md-description">
                <p>Participant-wise parameter estimates.</p>
              </div>
            </li>
            <li>
              <b><code>hessian</code></b>
                  (<code><span title="array">array</span> - <span title="like">like</span></code>)
              â€“
              <div class="doc-md-description">
                <p>Participant-wise Hessian matrices of the log posterior density function evaluated at the mode (i.e., MAP parameter estimates).</p>
              </div>
            </li>
            <li>
              <b><code>lme</code></b>
                  (<code><span title="float">float</span></code>)
              â€“
              <div class="doc-md-description">
                <p>Summed log model evidence.</p>
              </div>
            </li>
            <li>
              <b><code>iter_idx</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>0</code>
)
              â€“
              <div class="doc-md-description">
                <p>The iteration index. Default is 0.</p>
              </div>
            </li>
            <li>
              <b><code>chain_idx</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>0</code>
)
              â€“
              <div class="doc-md-description">
                <p>The chain index. Default is 0.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
<b><code>population_updates</code></b>(                  <code><span title="dict">dict</span></code>
)              â€“
              <div class="doc-md-description">
                <p>Dictionary of updated population-level parameters.</p>
              </div>
            </li>
            <li>
<b><code>param_snr</code></b>(                  <code><span title="array">array</span> - <span title="like">like</span></code>
)              â€“
              <div class="doc-md-description">
                <p>Standardised estimates of population-level means.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

    </div>

</div>



  </div>

    </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../optimisation/" class="btn btn-neutral float-left" title="cpm.optimisation"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../applications/" class="btn btn-neutral float-right" title="cpm.applications">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../optimisation/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../applications/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../.."></script>
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
