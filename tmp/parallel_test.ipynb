{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpm.utils import pandas_to_dict\n",
    "from cpm.generators import Value, Parameters, Wrapper\n",
    "import cpm.models\n",
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import ipyparallel as ipp\n",
    "\n",
    "data = pd.read_csv(\"simulated_data.csv\")\n",
    "\n",
    "experiment = pandas_to_dict(\n",
    "    data,\n",
    "    participant=\"ppt\",\n",
    "    stimuli=\"stimulus\",\n",
    "    feedback=\"reward\",\n",
    "    observed=\"responses\",\n",
    "    trial_number=\"trial\",\n",
    ")\n",
    "sd_start = numpy.random.uniform(0.1, 1, 2) * numpy.array([1, 10])\n",
    "mean_start = numpy.random.uniform(0, 1, 2) * numpy.array([1, 10])\n",
    "\n",
    "\n",
    "mean=[0.25, 5]\n",
    "sd=[0.25, 2.5]\n",
    "\n",
    "parameters = Parameters(\n",
    "    # freely varying parameters are indicated by specifying priors\n",
    "    alpha=Value(\n",
    "        value=0.5,\n",
    "        lower=1e-2,\n",
    "        upper=1,\n",
    "        prior=\"truncated_normal\",\n",
    "        args={\"mean\": mean[0], \"sd\": sd[0]},\n",
    "    ),\n",
    "    beta=Value(\n",
    "        value=2,\n",
    "        lower=0,\n",
    "        upper=10,\n",
    "        prior=\"truncated_normal\",\n",
    "        args={\"mean\": mean[1], \"sd\": mean[1]},\n",
    "    ),\n",
    "    values=numpy.ones(4) / 4,\n",
    ")\n",
    "\n",
    "@ipp.require('numpy')\n",
    "def model_analysis(parameters, trial):\n",
    "    \"\"\"\n",
    "    This function uses the model to estimate latent variables.\n",
    "    This means that the we use agents choices to estimate the values of the actions.\n",
    "    \"\"\"\n",
    "    # pull out the parameters\n",
    "    alpha = parameters.alpha\n",
    "    beta = parameters.beta\n",
    "    values = numpy.array(\n",
    "        parameters.values\n",
    "    )  # copy essentially prevents us from accidentally overwriting the original values\n",
    "    # pull out the trial information\n",
    "    stimulus = numpy.array(trial.get(\"trials\"))\n",
    "    feedback = numpy.array(trial.get(\"feedback\"))\n",
    "    choice = trial.get(\"observed\")\n",
    "    choice = choice.astype(int)\n",
    "\n",
    "    # activate the value of each available action\n",
    "    # here there are two possible actions, that can take up on 4 different values\n",
    "    # so we subset the values to only include the ones that are activated...\n",
    "    # ...according to which stimuli was presented\n",
    "    activation = values[stimulus - 1]\n",
    "    # convert the activations to a 2x1 matrix, where rows are actions/outcomes\n",
    "    activations = activation.reshape(2, 1)\n",
    "    # calculate a policy based on the activations\n",
    "    response = cpm.models.decision.Softmax(activations=activations, temperature=beta)\n",
    "    response.compute()  # compute the policy\n",
    "    if numpy.isnan(response.policies).any():\n",
    "        # if the policy is NaN for a given action, then we need to set it to 1\n",
    "        print(response.policies)\n",
    "        response.policies[numpy.isnan(response.policies)] = 1\n",
    "        response.policies = response.policies / numpy.sum(response.policies)\n",
    "    generated = response.choice()\n",
    "    # update the value of the chosen action\n",
    "    mute = numpy.zeros(4)  # mute learning for all cues not presented\n",
    "    mute[stimulus[choice] - 1] = 1  # unmute the learning for the chosen action\n",
    "    reward = feedback[choice]  # get the reward of the chosen action\n",
    "    teacher = numpy.array([reward])\n",
    "    update = cpm.models.learning.SeparableRule(\n",
    "        weights=values, feedback=teacher, input=mute, alpha=alpha\n",
    "    )\n",
    "    update.compute()\n",
    "    values = values + update.weights  # update the values\n",
    "    ## compile output\n",
    "    output = {\n",
    "        \"policy\": response.policies,  # policies\n",
    "        \"stimulus\": stimulus,  # stimulus presented\n",
    "        \"response\": generated,  # choice based on the policy\n",
    "        \"reward\": reward,  # reward of the chosen action\n",
    "        \"values\": values[0],  # updated values\n",
    "        \"change\": update.weights,  # change in the values\n",
    "        \"activation\": activations.flatten(),  # activation of the values\n",
    "        \"dependent\": numpy.array([response.policies[1]]),  # dependent variable\n",
    "    }\n",
    "    return output\n",
    "\n",
    "wrapper = Wrapper(model=model_analysis, parameters=parameters, data=data)\n",
    "\n",
    "\n",
    "from cpm.optimisation import minimise, FminBound\n",
    "from cpm.optimisation.minimise import LogLikelihood\n",
    "\n",
    "loss = LogLikelihood.bernoulli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization 1/5 from [0.53053937 1.55188626]\n",
      "Starting 5 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3f1f4582c04417aa9c7bff7852fd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization 2/5 from [0.01997607 8.81484471]\n",
      "Starting 5 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c1313c460e479abb571043b4c3baef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization 3/5 from [0.04300368 9.64040154]\n",
      "Starting 5 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f7050587834812b0fe96248df9d3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization 4/5 from [0.94083994 4.68481824]\n",
      "Starting 5 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ed4146a7ef444b9797dadd8b6e2fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization 5/5 from [0.47846832 4.24301131]\n",
      "Starting 5 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc569738cf84f16b8580bf581fcdeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?engine/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fit = FminBound(\n",
    "    model=wrapper,  # Wrapper class with the model we specified from before\n",
    "    data=experiment,  # the data as a list of dictionaries\n",
    "    minimisation=loss,\n",
    "    prior=False,\n",
    "    parallel=True,\n",
    "    cl=5,  # use all available cores\n",
    "    libraries=[\"numpy\", \"pandas\", \"cpm\"],  # libraries to import on the cluster\n",
    "    ppt_identifier=\"ppt\",\n",
    "    number_of_starts=5,\n",
    "    approx_grad=True,\n",
    "    pgtol=1e-10,\n",
    ")\n",
    "\n",
    "fit.optimise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
